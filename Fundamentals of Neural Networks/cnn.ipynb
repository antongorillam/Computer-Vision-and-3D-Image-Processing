{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "IMG_DIM = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('../mnist')\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "train_images, train_labels = np.array(train_images), np.array(train_labels)\n",
    "test_images, test_labels = np.array(test_images), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_idx = np.random.randint(len(test_images))\n",
    "plt.imshow(test_images[img_idx].reshape(IMG_DIM, IMG_DIM))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating validation set and convert to tensors\n",
    "from sklearn.model_selection import train_test_split \n",
    "import torch\n",
    "train_images.shape, train_labels.shape\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.10)\n",
    "\n",
    "n_train, n_val = train_images.shape[0], val_images.shape[0]\n",
    "train_images = train_images.reshape(n_train, 1, IMG_DIM, IMG_DIM)\n",
    "val_images = val_images.reshape(n_val, 1, IMG_DIM, IMG_DIM)\n",
    "test_images = test_images.reshape(test_images.shape[0], 1, IMG_DIM, IMG_DIM)\n",
    "\n",
    "train_images, val_images, test_images = torch.from_numpy(train_images).type(torch.FloatTensor), torch.from_numpy(val_images).type(torch.FloatTensor), torch.from_numpy(test_images).type(torch.FloatTensor)\n",
    "train_labels, val_labels, test_labels = train_labels.astype(int), val_labels.astype(int), test_labels.astype(int)\n",
    "train_labels, val_labels, test_labels = torch.from_numpy(train_labels), torch.from_numpy(val_labels), torch.from_numpy(test_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some variables\n",
    "DEVICE = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 150\n",
    "LEARNING_RATE = 1e-2\n",
    "DROP_OUT_RATE = 1e-1\n",
    "N_CLASSES = (train_labels.max() + 1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN\n",
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 13, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(13),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        ) \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(13*5*5, 180),\n",
    "            nn.Dropout(DROP_OUT_RATE),\n",
    "            nn.Linear(180, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import optim\n",
    "import time\n",
    "model = CNN()\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "\n",
    "train = torch.utils.data.TensorDataset(train_images,train_labels)\n",
    "val = torch.utils.data.TensorDataset(val_images, val_labels)\n",
    "test = torch.utils.data.TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "def train(train_loader, val_loader, test_loader):\n",
    "    writer = SummaryWriter()\n",
    "    train_accuaracy, train_loss = evaluate(train_loader)\n",
    "    val_accuaracy, val_loss = evaluate(val_loader)\n",
    "    \n",
    "    writer.add_scalar(\"Accuaracy/train\", train_accuaracy, 0)\n",
    "    writer.add_scalar(\"Accuaracy/val\", val_accuaracy, 0)\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, 0)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, 0)\n",
    "    tic = time.perf_counter()\n",
    "    toc = time.perf_counter()\n",
    "    time_format = time.strftime(\"%M:%S\", time.gmtime(toc - tic))\n",
    "    print(f\"Time elapsed: {time_format}, epoch: {str(0).zfill(2)}/{N_EPOCHS}, train loss: {train_loss:.2f}, train accuaracy: {train_accuaracy:.2f}, val loss: {val_loss:.2f}, val accuaracy: {val_accuaracy:.2f}\")\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS+1):\n",
    "        \n",
    "        correctly_classified = 0\n",
    "        total_classified = 0\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            train = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            out = model(train)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predicted = torch.max(out.data, 1)[1]\n",
    "            total_classified += len(labels)\n",
    "            correctly_classified += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuaracy, val_loss = evaluate(val_loader)\n",
    "        train_accuaracy = 100 * correctly_classified / total_classified  \n",
    "        writer.add_scalar(\"Accuaracy/train\", train_accuaracy, epoch)\n",
    "        writer.add_scalar(\"Accuaracy/val\", val_accuaracy, epoch)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "        toc = time.perf_counter()\n",
    "        time_format = time.strftime(\"%M:%S\", time.gmtime(toc - tic))\n",
    "        print(f\"Time elapsed: {time_format}, epoch: {str(epoch).zfill(2)}/{N_EPOCHS}, train loss: {train_loss:.2f}, train accuaracy: {train_accuaracy:.2f}, val loss: {val_loss:.2f}, val accuaracy: {val_accuaracy:.2f}\")\n",
    "    writer.flush()\n",
    "\n",
    "def evaluate(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correctly_classified = 0\n",
    "        total_classified = 0\n",
    "        loss = 0\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            \n",
    "            train, labels = Variable(images), Variable(labels)\n",
    "            out = model(train)\n",
    "            loss = criterion(out, labels)\n",
    "            loss += loss.item()\n",
    "            predicted = torch.max(out.data, 1)[1]\n",
    "            total_classified += len(labels)\n",
    "            correctly_classified += (predicted == labels).sum().item()\n",
    "\n",
    "    accuaracy = 100 * correctly_classified / total_classified\n",
    "    return accuaracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 00:00, epoch: 00/20, train loss: 4.78, train accuaracy: 12.65, val loss: 4.78, val accuaracy: 12.73\n",
      "Time elapsed: 00:26, epoch: 01/20, train loss: 72.53, train accuaracy: 94.18, val loss: 0.10, val accuaracy: 98.02\n",
      "Time elapsed: 00:54, epoch: 02/20, train loss: 21.32, train accuaracy: 98.20, val loss: 0.04, val accuaracy: 98.42\n",
      "Time elapsed: 01:26, epoch: 03/20, train loss: 17.59, train accuaracy: 98.50, val loss: 0.17, val accuaracy: 98.58\n",
      "Time elapsed: 01:51, epoch: 04/20, train loss: 15.22, train accuaracy: 98.69, val loss: 0.03, val accuaracy: 98.50\n",
      "Time elapsed: 02:16, epoch: 05/20, train loss: 14.34, train accuaracy: 98.72, val loss: 0.04, val accuaracy: 98.15\n",
      "Time elapsed: 02:42, epoch: 06/20, train loss: 12.49, train accuaracy: 98.86, val loss: 0.24, val accuaracy: 98.55\n",
      "Time elapsed: 03:11, epoch: 07/20, train loss: 13.49, train accuaracy: 98.86, val loss: 0.16, val accuaracy: 98.52\n",
      "Time elapsed: 03:37, epoch: 08/20, train loss: 13.39, train accuaracy: 98.84, val loss: 0.00, val accuaracy: 98.52\n",
      "Time elapsed: 04:05, epoch: 09/20, train loss: 11.66, train accuaracy: 98.99, val loss: 0.02, val accuaracy: 98.57\n",
      "Time elapsed: 04:29, epoch: 10/20, train loss: 11.80, train accuaracy: 99.03, val loss: 0.01, val accuaracy: 97.37\n",
      "Time elapsed: 04:54, epoch: 11/20, train loss: 11.81, train accuaracy: 99.07, val loss: 0.33, val accuaracy: 98.52\n",
      "Time elapsed: 05:18, epoch: 12/20, train loss: 11.94, train accuaracy: 99.01, val loss: 0.26, val accuaracy: 98.37\n",
      "Time elapsed: 05:49, epoch: 13/20, train loss: 13.66, train accuaracy: 98.93, val loss: 0.52, val accuaracy: 98.65\n",
      "Time elapsed: 06:14, epoch: 14/20, train loss: 10.60, train accuaracy: 99.15, val loss: 0.26, val accuaracy: 98.18\n",
      "Time elapsed: 06:38, epoch: 15/20, train loss: 12.00, train accuaracy: 99.01, val loss: 0.01, val accuaracy: 98.80\n",
      "Time elapsed: 07:03, epoch: 16/20, train loss: 11.56, train accuaracy: 99.11, val loss: 0.18, val accuaracy: 98.72\n",
      "Time elapsed: 07:27, epoch: 17/20, train loss: 10.15, train accuaracy: 99.16, val loss: 0.06, val accuaracy: 98.70\n",
      "Time elapsed: 07:52, epoch: 18/20, train loss: 12.21, train accuaracy: 99.05, val loss: 0.18, val accuaracy: 98.80\n",
      "Time elapsed: 08:17, epoch: 19/20, train loss: 10.12, train accuaracy: 99.22, val loss: 0.14, val accuaracy: 98.78\n",
      "Time elapsed: 08:48, epoch: 20/20, train loss: 12.91, train accuaracy: 99.06, val loss: 0.21, val accuaracy: 98.33\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test evaluation score: 98.72\n"
     ]
    }
   ],
   "source": [
    "test_accuaracy, _ = evaluate(test_loader)\n",
    "print(f\"Final test evaluation score: {test_accuaracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "279c8b50df304f745eb07ab34d4c9440a9c9a9723aa7cb81c69d60aaa8fdc250"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('experiments')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
