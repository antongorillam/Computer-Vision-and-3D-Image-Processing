{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "IMG_DIM = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('../mnist')\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "train_images, train_labels = np.array(train_images), np.array(train_labels)\n",
    "test_images, test_labels = np.array(test_images), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_idx = np.random.randint(len(test_images))\n",
    "plt.imshow(test_images[img_idx].reshape(IMG_DIM, IMG_DIM))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating validation set and convert to tensors\n",
    "from sklearn.model_selection import train_test_split \n",
    "import torch\n",
    "train_images.shape, train_labels.shape\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.10)\n",
    "\n",
    "n_train, n_val = train_images.shape[0], val_images.shape[0]\n",
    "train_images = train_images.reshape(n_train, 1, IMG_DIM, IMG_DIM)\n",
    "val_images = val_images.reshape(n_val, 1, IMG_DIM, IMG_DIM)\n",
    "test_images = test_images.reshape(test_images.shape[0], 1, IMG_DIM, IMG_DIM)\n",
    "\n",
    "train_images, val_images, test_images = torch.from_numpy(train_images).type(torch.FloatTensor), torch.from_numpy(val_images).type(torch.FloatTensor), torch.from_numpy(test_images).type(torch.FloatTensor)\n",
    "train_labels, val_labels, test_labels = train_labels.astype(int), val_labels.astype(int), test_labels.astype(int)\n",
    "train_labels, val_labels, test_labels = torch.from_numpy(train_labels), torch.from_numpy(val_labels), torch.from_numpy(test_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some variables\n",
    "DEVICE = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 150\n",
    "LEARNING_RATE = 1e-2\n",
    "DROP_OUT_RATE = 1e-1\n",
    "N_CLASSES = (train_labels.max() + 1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN\n",
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 13, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(13),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        ) \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(13*5*5, 180),\n",
    "            nn.Dropout(DROP_OUT_RATE),\n",
    "            nn.Linear(180, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import optim\n",
    "model = CNN()\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "\n",
    "train = torch.utils.data.TensorDataset(train_images,train_labels)\n",
    "val = torch.utils.data.TensorDataset(val_images, val_labels)\n",
    "test = torch.utils.data.TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "def train(train_loader, val_loader, test_loader):\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        correctly_classified = 0\n",
    "        total_classified = 0\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            train = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            out = model(train)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predicted = torch.max(out.data, 1)[1]\n",
    "            total_classified += len(labels)\n",
    "            correctly_classified += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuaracy, val_loss = evaluate(val_loader)\n",
    "        train_accuaracy = 100 * correctly_classified / total_classified  \n",
    "        writer.add_scalar(\"Accuaracy/train\", train_accuaracy, epoch)\n",
    "        writer.add_scalar(\"Accuaracy/val\", val_accuaracy, epoch)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "        print(f\"Epoch: {epoch+1}/{N_EPOCHS}, loss: {train_loss}, accuaracy: {train_accuaracy}\")\n",
    "\n",
    "    writer.flush()\n",
    "\n",
    "def evaluate(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correctly_classified = 0\n",
    "        total_classified = 0\n",
    "        loss = 0\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            \n",
    "            train, labels = Variable(images), Variable(labels)\n",
    "            out = model(train)\n",
    "            loss = criterion(out, labels)\n",
    "            loss += loss.item()\n",
    "            predicted = torch.max(out.data, 1)[1]\n",
    "            total_classified += len(labels)\n",
    "            correctly_classified += (predicted == labels).sum().item()\n",
    "\n",
    "    accuaracy = 100 * correctly_classified / total_classified\n",
    "    return accuaracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 23:58:44.057920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-08 23:58:44.057967: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test evaluation score: 97.98\n"
     ]
    }
   ],
   "source": [
    "test_accuaracy, _ = evaluate(test_loader)\n",
    "print(f\"Final test evaluation score: {test_accuaracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "279c8b50df304f745eb07ab34d4c9440a9c9a9723aa7cb81c69d60aaa8fdc250"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('experiments')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
