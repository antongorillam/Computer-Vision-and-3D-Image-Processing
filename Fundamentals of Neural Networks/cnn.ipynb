{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "IMG_DIM = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('../mnist')\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "train_images, train_labels = np.array(train_images), np.array(train_labels)\n",
    "test_images, test_labels = np.array(test_images), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_idx = np.random.randint(len(test_images))\n",
    "plt.imshow(test_images[img_idx].reshape(IMG_DIM, IMG_DIM))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Creating validation set and convert to tensors\n",
    "from sklearn.model_selection import train_test_split \n",
    "import torch\n",
    "train_images.shape, train_labels.shape\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.10)\n",
    "\n",
    "n_train, n_val = train_images.shape[0], val_images.shape[0]\n",
    "train_images = train_images.reshape(n_train, 1, IMG_DIM, IMG_DIM)\n",
    "val_images = val_images.reshape(n_val, 1, IMG_DIM, IMG_DIM)\n",
    "test_images = test_images.reshape(test_images.shape[0], 1, IMG_DIM, IMG_DIM)\n",
    "\n",
    "train_images, val_images, test_images = torch.from_numpy(train_images).type(torch.FloatTensor), torch.from_numpy(val_images).type(torch.FloatTensor), torch.from_numpy(test_images).type(torch.FloatTensor)\n",
    "train_labels, val_labels, test_labels = train_labels.astype(int), val_labels.astype(int), test_labels.astype(int)\n",
    "train_labels, val_labels, test_labels = torch.from_numpy(train_labels), torch.from_numpy(val_labels), torch.from_numpy(test_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some variables\n",
    "DEVICE = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 150\n",
    "LEARNING_RATE = 1e-2\n",
    "DROP_OUT_RATE = 1e-1\n",
    "N_CLASSES = (train_labels.max() + 1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN\n",
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 13, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(13),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(13*5*5, 180),\n",
    "            nn.Dropout(DROP_OUT_RATE),\n",
    "            nn.Linear(180, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "model = CNN()\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "\n",
    "train = torch.utils.data.TensorDataset(train_images,train_labels)\n",
    "val = torch.utils.data.TensorDataset(val_images, val_labels)\n",
    "test = torch.utils.data.TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "def train(train_loader, val_loader, test_loader):\n",
    "    writer = SummaryWriter()\n",
    "    train_accuaracy, train_loss = evaluate(train_loader)\n",
    "    val_accuaracy, val_loss = evaluate(val_loader)\n",
    "    \n",
    "    writer.add_scalar(\"Accuaracy/train\", train_accuaracy, 0)\n",
    "    writer.add_scalar(\"Accuaracy/val\", val_accuaracy, 0)\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, 0)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, 0)\n",
    "    tic = time.perf_counter()\n",
    "    toc = time.perf_counter()\n",
    "    time_format = time.strftime(\"%M:%S\", time.gmtime(toc - tic))\n",
    "    print(f\"Time elapsed: {time_format}, epoch: {str(0).zfill(2)}/{N_EPOCHS}, train loss: {train_loss:.2f}, train accuaracy: {train_accuaracy:.2f}, val loss: {val_loss:.2f}, val accuaracy: {val_accuaracy:.2f}\")\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS+1):\n",
    "        \n",
    "        correctly_classified = 0\n",
    "        total_classified = 0\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            train = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            out = model(train)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predicted = torch.max(out.data, 1)[1]\n",
    "            total_classified += len(labels)\n",
    "            correctly_classified += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuaracy, val_loss = evaluate(val_loader)\n",
    "        train_accuaracy = 100 * correctly_classified / total_classified  \n",
    "        writer.add_scalar(\"Accuaracy/train\", train_accuaracy, epoch)\n",
    "        writer.add_scalar(\"Accuaracy/val\", val_accuaracy, epoch)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "        toc = time.perf_counter()\n",
    "        time_format = time.strftime(\"%M:%S\", time.gmtime(toc - tic))\n",
    "        print(f\"Time elapsed: {time_format}, epoch: {str(epoch).zfill(2)}/{N_EPOCHS}, train loss: {train_loss:.2f}, train accuaracy: {train_accuaracy:.2f}, val loss: {val_loss:.2f}, val accuaracy: {val_accuaracy:.2f}\")\n",
    "    writer.flush()\n",
    "\n",
    "def evaluate(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correctly_classified = 0\n",
    "        total_classified = 0\n",
    "        loss = 0\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            \n",
    "            train, labels = Variable(images), Variable(labels)\n",
    "            out = model(train)\n",
    "            loss = criterion(out, labels)\n",
    "            loss += loss.item()\n",
    "            predicted = torch.max(out.data, 1)[1]\n",
    "            total_classified += len(labels)\n",
    "            correctly_classified += (predicted == labels).sum().item()\n",
    "\n",
    "    accuaracy = 100 * correctly_classified / total_classified\n",
    "    return accuaracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 00:00, epoch: 00/20, train loss: 0.19, train accuaracy: 96.28, val loss: 0.21, val accuaracy: 95.58\n",
      "Time elapsed: 00:30, epoch: 01/20, train loss: 31.01, train accuaracy: 97.41, val loss: 0.19, val accuaracy: 98.22\n",
      "Time elapsed: 01:03, epoch: 02/20, train loss: 20.34, train accuaracy: 98.33, val loss: 0.11, val accuaracy: 97.90\n",
      "Time elapsed: 01:34, epoch: 03/20, train loss: 17.30, train accuaracy: 98.56, val loss: 0.08, val accuaracy: 98.15\n",
      "Time elapsed: 02:07, epoch: 04/20, train loss: 14.73, train accuaracy: 98.69, val loss: 0.17, val accuaracy: 97.75\n",
      "Time elapsed: 02:40, epoch: 05/20, train loss: 13.59, train accuaracy: 98.82, val loss: 0.09, val accuaracy: 98.27\n",
      "Time elapsed: 03:08, epoch: 06/20, train loss: 14.22, train accuaracy: 98.78, val loss: 0.15, val accuaracy: 98.32\n",
      "Time elapsed: 03:40, epoch: 07/20, train loss: 13.69, train accuaracy: 98.86, val loss: 0.26, val accuaracy: 98.05\n",
      "Time elapsed: 04:14, epoch: 08/20, train loss: 12.26, train accuaracy: 98.96, val loss: 0.41, val accuaracy: 98.18\n",
      "Time elapsed: 04:47, epoch: 09/20, train loss: 12.76, train accuaracy: 98.95, val loss: 0.02, val accuaracy: 98.45\n",
      "Time elapsed: 05:19, epoch: 10/20, train loss: 11.96, train accuaracy: 98.99, val loss: 0.06, val accuaracy: 98.47\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test evaluation score: 98.72\n"
     ]
    }
   ],
   "source": [
    "test_accuaracy, _ = evaluate(test_loader)\n",
    "print(f\"Final test evaluation score: {test_accuaracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "279c8b50df304f745eb07ab34d4c9440a9c9a9723aa7cb81c69d60aaa8fdc250"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('experiments')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
